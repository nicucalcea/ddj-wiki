{
  "cells": [
    {
      "cell_type": "raw",
      "id": "c250529d-3381-4cf1-b9e1-da590fa12691",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "---\n",
        "title: \"AI classification agent\"\n",
        "href: python-classification-agent\n",
        "format:\n",
        "  html:\n",
        "    code-links:\n",
        "      - text: Download notebook\n",
        "        icon: download\n",
        "        href: https://github.com/nicucalcea/ddj-wiki/blob/main/ai/python-classification-rag.ipynb\n",
        "        target: _blank\n",
        "      - text: Open in Google Colab\n",
        "        icon: google\n",
        "        href: https://colab.research.google.com/github/nicucalcea/ddj-wiki/blob/main/ai/python-classification-rag.ipynb\n",
        "        target: _blank\n",
        "execute: \n",
        "  cache: true\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vO-mZV3OGrm_"
      },
      "source": [
        "You find yourself staring at a dataset with tens or hundreds of thousands of rows. Maybe you want to get up-to-date FOIA contact details for all government departments in your country, or to find out which political donors have links to the fossil fuels industry. What do you do?\n",
        "\n",
        "Large Language Models (LLMs) like those powering ChatGPT can help journalists automate simple research and classification tasks that would take an unreasonably long time to do otherwise.\n",
        "\n",
        "In this session, we'll outline how to use LLMs, search engines and web scraping to help us identify links between Donald Trump and his donors. You can [download the notebook](https://github.com/nicucalcea/ddj-wiki/blob/main/ai/python-classification-rag.ipynb) and run it yourself, or you can [run it in the cloud using Google Colab](https://colab.research.google.com/github/nicucalcea/ddj-wiki/blob/main/ai/python-classification-rag.ipynb). Both links also in the sidebar to the right, or at the bottom of the page on mobile."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nd-jWkBqd8jH"
      },
      "source": [
        "## Install and load libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First, we'll need to install some libraries to help us call different LLMs and retrieve search results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jbn2VKx1gj4W"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2mUsing Python 3.13.3 environment at: C:\\Users\\NicuCalcea\\Projects\\ddj-wiki\\.venv\u001b[0m\n",
            "\u001b[2mResolved \u001b[1m72 packages\u001b[0m \u001b[2min 1.38s\u001b[0m\u001b[0m\n",
            "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m botocore \u001b[2m(12.9MiB)\u001b[0m\n",
            "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m pydantic-core \u001b[2m(1.9MiB)\u001b[0m\n",
            "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m tokenizers \u001b[2m(2.3MiB)\u001b[0m\n",
            " \u001b[32m\u001b[1mDownloading\u001b[0m\u001b[39m pydantic-core\n",
            " \u001b[32m\u001b[1mDownloading\u001b[0m\u001b[39m tokenizers\n",
            " \u001b[32m\u001b[1mDownloading\u001b[0m\u001b[39m botocore\n",
            "\u001b[2mPrepared \u001b[1m65 packages\u001b[0m \u001b[2min 36.22s\u001b[0m\u001b[0m\n",
            "\u001b[2mInstalled \u001b[1m65 packages\u001b[0m \u001b[2min 4.76s\u001b[0m\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mannotated-types\u001b[0m\u001b[2m==0.7.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1manthropic\u001b[0m\u001b[2m==0.51.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1manyio\u001b[0m\u001b[2m==4.9.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1margcomplete\u001b[0m\u001b[2m==3.6.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mboto3\u001b[0m\u001b[2m==1.38.14\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mbotocore\u001b[0m\u001b[2m==1.38.14\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mcachetools\u001b[0m\u001b[2m==5.5.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mcertifi\u001b[0m\u001b[2m==2025.4.26\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mcharset-normalizer\u001b[0m\u001b[2m==3.4.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mclick\u001b[0m\u001b[2m==8.2.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mcohere\u001b[0m\u001b[2m==5.15.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mdeprecated\u001b[0m\u001b[2m==1.2.18\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mdistro\u001b[0m\u001b[2m==1.9.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1meval-type-backport\u001b[0m\u001b[2m==0.2.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mfasta2a\u001b[0m\u001b[2m==0.2.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mfastavro\u001b[0m\u001b[2m==1.10.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mfilelock\u001b[0m\u001b[2m==3.18.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mfsspec\u001b[0m\u001b[2m==2025.3.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mgoogle-auth\u001b[0m\u001b[2m==2.40.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mgriffe\u001b[0m\u001b[2m==1.7.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mgroq\u001b[0m\u001b[2m==0.24.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mh11\u001b[0m\u001b[2m==0.16.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mhttpcore\u001b[0m\u001b[2m==1.0.9\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mhttpx\u001b[0m\u001b[2m==0.28.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mhttpx-sse\u001b[0m\u001b[2m==0.4.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mhuggingface-hub\u001b[0m\u001b[2m==0.31.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1midna\u001b[0m\u001b[2m==3.10\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mimportlib-metadata\u001b[0m\u001b[2m==8.6.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mjiter\u001b[0m\u001b[2m==0.9.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mjmespath\u001b[0m\u001b[2m==1.0.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mlogfire-api\u001b[0m\u001b[2m==3.15.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmarkdown-it-py\u001b[0m\u001b[2m==3.0.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmcp\u001b[0m\u001b[2m==1.8.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmdurl\u001b[0m\u001b[2m==0.1.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmistralai\u001b[0m\u001b[2m==1.7.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mopenai\u001b[0m\u001b[2m==1.78.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mopentelemetry-api\u001b[0m\u001b[2m==1.33.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpyasn1\u001b[0m\u001b[2m==0.6.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpyasn1-modules\u001b[0m\u001b[2m==0.4.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpydantic\u001b[0m\u001b[2m==2.11.4\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpydantic-ai\u001b[0m\u001b[2m==0.2.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpydantic-ai-slim\u001b[0m\u001b[2m==0.2.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpydantic-core\u001b[0m\u001b[2m==2.33.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpydantic-evals\u001b[0m\u001b[2m==0.2.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpydantic-graph\u001b[0m\u001b[2m==0.2.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpydantic-settings\u001b[0m\u001b[2m==2.9.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpython-dotenv\u001b[0m\u001b[2m==1.1.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpython-multipart\u001b[0m\u001b[2m==0.0.20\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpyyaml\u001b[0m\u001b[2m==6.0.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mrequests\u001b[0m\u001b[2m==2.32.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mrich\u001b[0m\u001b[2m==14.0.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mrsa\u001b[0m\u001b[2m==4.9.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1ms3transfer\u001b[0m\u001b[2m==0.12.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1msniffio\u001b[0m\u001b[2m==1.3.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1msse-starlette\u001b[0m\u001b[2m==2.3.5\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mstarlette\u001b[0m\u001b[2m==0.46.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtokenizers\u001b[0m\u001b[2m==0.21.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtqdm\u001b[0m\u001b[2m==4.67.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtypes-requests\u001b[0m\u001b[2m==2.32.0.20250328\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtyping-extensions\u001b[0m\u001b[2m==4.13.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtyping-inspection\u001b[0m\u001b[2m==0.4.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1murllib3\u001b[0m\u001b[2m==2.4.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1muvicorn\u001b[0m\u001b[2m==0.34.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mwrapt\u001b[0m\u001b[2m==1.17.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mzipp\u001b[0m\u001b[2m==3.21.0\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!uv pip install pandas\n",
        "!uv pip install pydantic-ai\n",
        "!uv pip install duckduckgo-search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then, we'll import those libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "# maths\n",
        "import pandas as pd\n",
        "\n",
        "# scraping\n",
        "from urllib import request\n",
        "import ssl\n",
        "import requests\n",
        "\n",
        "# AI\n",
        "from pydantic_ai import Agent\n",
        "from pydantic_ai.common_tools.duckduckgo import duckduckgo_search_tool"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, we need to define some of the API keys we'll be using. You can get your own [OpenAI API key](https://platform.openai.com/account/api-keys) or one from another provider."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lisUctaVd_K8"
      },
      "outputs": [],
      "source": [
        "OPENAI_API_KEY=\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z04YaWN5LEsy"
      },
      "source": [
        "## Prep data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We'll work with some data from the US Federal Election Commission (FEC) on [donations to Donald Trump's inaugural committee](https://docquery.fec.gov/cgi-bin/forms/C00894162/1889684/f132). Because a downloadable version isn't provided, we'll scrape the data directly from the website."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                  Name                                            Address  \\\n",
            "0  A10 ASSOCIATES, LLC            214 COMMERCIAL ST #202 MALDEN, MA 02148   \n",
            "1        DANIEL ABBATE  340 ROYAL POINCIANA WAY STE 317 PALM BEACH, FL...   \n",
            "2  ABBOTT LABORATORIES         100 ABBOTT PARK ROAD ABBOTT PARK, IL 60064   \n",
            "3          CAROL ADAMS            6125 LUTHER LN STE 245 DALLAS, TX 75225   \n",
            "4         HAYDEN ADAMS               524 BROADWAY FL 6 NEW YORK, NY 10013   \n",
            "\n",
            "  Date Donation Received Donation Amount Donor's Aggregate Donations To Date  \n",
            "0             01/10/2025       $50000.00                           $50000.00  \n",
            "1             01/01/2025       $25000.00                           $25000.00  \n",
            "2             12/24/2024      $500000.00                          $500000.00  \n",
            "3             01/13/2025      $250000.00                          $250000.00  \n",
            "4             01/09/2025      $245727.56                          $245727.56  \n"
          ]
        }
      ],
      "source": [
        "response = request.urlopen(\"https://docquery.fec.gov/cgi-bin/forms/C00894162/1889684/f132\",\n",
        "                           context=ssl._create_unverified_context())\n",
        "html = response.read()\n",
        "\n",
        "fec_raw = pd.read_html(html)[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We need to fix some of the formatting issues, like dollar signs and converting dates to a more standard format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fec = fec_raw.copy()\n",
        "fec = fec.iloc[:-1] # the last row is a summary\n",
        "\n",
        "fec['Date Donation Received'] = pd.to_datetime(\n",
        "    fec['Date Donation Received'], \n",
        "    format='%m/%d/%Y'  # Format for \"31/12/2025\"\n",
        ")\n",
        "\n",
        "fec['Donation Amount'] = fec['Donation Amount'].str.replace('$', '', regex=False)\n",
        "fec['Donation Amount'] = pd.to_numeric(fec['Donation Amount'])\n",
        "\n",
        "fec = fec.drop(columns=[\"Donor's Aggregate Donations To Date\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Some donors donated multiple times, so we'll want to group them together and only classify them once."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "fec_total = fec.groupby('Name')['Donation Amount'].sum().reset_index()\n",
        "fec_total = fec_total.sort_values(by='Donation Amount', ascending=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We should be ready to go. Let's see what the data looks like."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.microsoft.datawrangler.viewer.v0+json": {
              "columns": [
                {
                  "name": "index",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "Name",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "Donation Amount",
                  "rawType": "float64",
                  "type": "float"
                }
              ],
              "conversionMethod": "pd.DataFrame",
              "ref": "72a448dd-bd53-4951-96d7-b626988a17d3",
              "rows": [
                [
                  "618",
                  "PILGRIM'S PRIDE CORPORATION",
                  "5000000.0"
                ],
                [
                  "652",
                  "RIPPLE LABS, INC.",
                  "4889345.33"
                ],
                [
                  "824",
                  "WARREN A STEPHENS",
                  "4000000.0"
                ],
                [
                  "667",
                  "ROBINHOOD MARKETS, INC.",
                  "2000000.0"
                ],
                [
                  "360",
                  "JARED ISAACMAN",
                  "2000000.0"
                ],
                [
                  "745",
                  "TANG FAMILY TRUST DTD",
                  "2000000.0"
                ],
                [
                  "139",
                  "CHEVRON PRODUCTS COMPANY",
                  "2000000.0"
                ],
                [
                  "520",
                  "MELISSA ARGYROS",
                  "2000000.0"
                ],
                [
                  "807",
                  "VAPOR TECHNOLOGY ASSOCIATION",
                  "1250000.0"
                ],
                [
                  "43",
                  "ANTHONY JOSEPH PRATT",
                  "1100000.0"
                ],
                [
                  "109",
                  "CANTOR FITZGERALD AND CO",
                  "1047000.0"
                ],
                [
                  "404",
                  "JPMORGAN CHASE & CO.",
                  "1033057.85"
                ],
                [
                  "245",
                  "FEDEX CORPORATION",
                  "1000351.19"
                ],
                [
                  "308",
                  "HIMS, INC.",
                  "1000000.01"
                ],
                [
                  "625",
                  "QUALCOMM INCORPORATED",
                  "1000000.0"
                ],
                [
                  "15",
                  "ALEXANDER SHUSTOROVISH",
                  "1000000.0"
                ],
                [
                  "93",
                  "BREEZE SMOKE LLC",
                  "1000000.0"
                ],
                [
                  "521",
                  "MERCK SHARP AND DOHME LLC",
                  "1000000.0"
                ],
                [
                  "92",
                  "BRADLEY WAYNE HUGHES JR",
                  "1000000.0"
                ],
                [
                  "811",
                  "VENTURE GLOBAL LNG, INC",
                  "1000000.0"
                ],
                [
                  "808",
                  "VAXCYTE, INC",
                  "1000000.0"
                ],
                [
                  "514",
                  "MCDONALD'S CORPORATION",
                  "1000000.0"
                ],
                [
                  "616",
                  "PHRMA",
                  "1000000.0"
                ],
                [
                  "614",
                  "PHILLIP J SAROFIM",
                  "1000000.0"
                ],
                [
                  "55",
                  "ASPECT HOLDINGS, LLC",
                  "1000000.0"
                ],
                [
                  "572",
                  "NNENNA PETERS",
                  "1000000.0"
                ],
                [
                  "73",
                  "BENFAM HOLDINGS PR LLC",
                  "1000000.0"
                ],
                [
                  "47",
                  "APPLIED MATERIALS INC.",
                  "1000000.0"
                ],
                [
                  "56",
                  "AT&T SERVICES, INC",
                  "1000000.0"
                ],
                [
                  "592",
                  "PAUL ELLIOTT SINGER",
                  "1000000.0"
                ],
                [
                  "599",
                  "PAYWARD INC",
                  "1000000.0"
                ],
                [
                  "619",
                  "POET, LLC",
                  "1000000.0"
                ],
                [
                  "584",
                  "ONDO FINANCE, INC.",
                  "1000000.0"
                ],
                [
                  "71",
                  "BAYER",
                  "1000000.0"
                ],
                [
                  "580",
                  "OCCIDENTAL PETROLEUM CORPORATION",
                  "1000000.0"
                ],
                [
                  "577",
                  "NVIDIA CORPORATION",
                  "1000000.0"
                ],
                [
                  "66",
                  "BARABARA GRIMM MARSHALL",
                  "1000000.0"
                ],
                [
                  "65",
                  "BANK OZK",
                  "1000000.0"
                ],
                [
                  "544",
                  "MIRIAM ADELSON",
                  "1000000.0"
                ],
                [
                  "524",
                  "META",
                  "1000000.0"
                ],
                [
                  "565",
                  "NEXTERA ENERGY",
                  "1000000.0"
                ],
                [
                  "563",
                  "NEW LEVANT INITIATIVE LLC",
                  "1000000.0"
                ],
                [
                  "103",
                  "BROADCOM, INC",
                  "1000000.0"
                ],
                [
                  "78",
                  "BLACKROCK FINANCIAL MANAGEMENT INC",
                  "1000000.0"
                ],
                [
                  "559",
                  "NATIONAL ASSOCIATION OF MANUFACTURERS",
                  "1000000.0"
                ],
                [
                  "51",
                  "ASHBRITT, INC.",
                  "1000000.0"
                ],
                [
                  "58",
                  "AUSTIN FAMILY TRUST",
                  "1000000.0"
                ],
                [
                  "602",
                  "PERPLEXITY AI, INC.",
                  "1000000.0"
                ],
                [
                  "500",
                  "MARLENE RICKETTS",
                  "1000000.0"
                ],
                [
                  "680",
                  "RTW INVESTMENTS, LP",
                  "1000000.0"
                ]
              ],
              "shape": {
                "columns": 2,
                "rows": 845
              }
            },
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>Donation Amount</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>618</th>\n",
              "      <td>PILGRIM'S PRIDE CORPORATION</td>\n",
              "      <td>5000000.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>652</th>\n",
              "      <td>RIPPLE LABS, INC.</td>\n",
              "      <td>4889345.33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>824</th>\n",
              "      <td>WARREN A STEPHENS</td>\n",
              "      <td>4000000.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>667</th>\n",
              "      <td>ROBINHOOD MARKETS, INC.</td>\n",
              "      <td>2000000.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>360</th>\n",
              "      <td>JARED ISAACMAN</td>\n",
              "      <td>2000000.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>365</th>\n",
              "      <td>JEFF STIBEL</td>\n",
              "      <td>1000.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>144</th>\n",
              "      <td>CHRISTOPHER SHEERON</td>\n",
              "      <td>1000.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>192</th>\n",
              "      <td>DAVID RATLIFF</td>\n",
              "      <td>516.53</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>438</th>\n",
              "      <td>KURT FOULDS</td>\n",
              "      <td>500.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>799</th>\n",
              "      <td>UNITEMIZED TOTAL</td>\n",
              "      <td>146.95</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>845 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                            Name  Donation Amount\n",
              "618  PILGRIM'S PRIDE CORPORATION       5000000.00\n",
              "652            RIPPLE LABS, INC.       4889345.33\n",
              "824            WARREN A STEPHENS       4000000.00\n",
              "667      ROBINHOOD MARKETS, INC.       2000000.00\n",
              "360               JARED ISAACMAN       2000000.00\n",
              "..                           ...              ...\n",
              "365                  JEFF STIBEL          1000.00\n",
              "144          CHRISTOPHER SHEERON          1000.00\n",
              "192                DAVID RATLIFF           516.53\n",
              "438                  KURT FOULDS           500.00\n",
              "799             UNITEMIZED TOTAL           146.95\n",
              "\n",
              "[845 rows x 2 columns]"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fec_total"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Searching and scraping"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First, we need a programmatic way to search the internet.\n",
        "\n",
        "We could try simply scraping search results from Google like we did with the FEC data, but Google doesn't like that, and they will put various roadblocks in your way such as CAPTCHAs, rate limits or even blocking your IP address. Instead, they want you to pay for their [Custom Search API](https://developers.google.com/custom-search/v1/overview), which is paid and limited to 10k queries per day.\n",
        "\n",
        "Other search engines like Brave provide generous free tiers and more reasonable pricing, and there are some search engines that specifically cater to AI applications, like [Tavily](https://tavily.com/) and [Perplexity](https://docs.perplexity.ai/home).\n",
        "\n",
        "We'll use the DuckDuckGo API since it's free (but rate-limited), doesn't require signing up for an API key, and comes with PydanticAI."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We also want to give our AI the ability to visit each of those search results and extract the text from there. We'll use a library called [Trafilatura](https://github.com/adbar/trafilatura) since it extract the main text without headers, footers and other irrelevant bits that we probably don't need for the classification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_text(urls):\n",
        "    results = []\n",
        "\n",
        "    for url in urls:\n",
        "        print(f\"Scraping {url}...\")\n",
        "        try:\n",
        "            response = requests.get(url, timeout=30, verify=False)  # Note: verify=False is not recommended for production use\n",
        "            response.raise_for_status()  # Raises an HTTPError for bad responses\n",
        "            extracted_text = extract(response.text, output_format=\"markdown\")\n",
        "            results.append((url, extracted_text))\n",
        "        except requests.RequestException as e:\n",
        "            print(f\"Error scraping {url}: {str(e)}\")\n",
        "            results.append((url, f\"Error: {str(e)}\"))\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Agents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In an earlier iteration of this project, we searched the internet for each one of those donors using the exact name as listed in the data, extracted the first 10 results, scraped them, and then fed them to an LLM.\n",
        "\n",
        "Since then, AI agents have become a lot more prominent. Agents are systems where LLMs are allowed to choose their own steps, use tools appropriate for different tasks and make decisions about when to stop.\n",
        "\n",
        "The code required to set up an agent from scratch is fairly simple, but there are several frameworks which come with batteries included. We'll use [PydanticAI](https://ai.pydantic.dev), but most of them are similar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "ename": "OpenAIError",
          "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mOpenAIError\u001b[39m                               Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[42]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m agent = \u001b[43mAgent\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mopenai:gpt-4.1-mini\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mduckduckgo_search_tool\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43msystem_prompt\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mAnswer the question to the best of your abilities, using DuckDuckGo search results.\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m result = agent.run_sync(\n\u001b[32m      8\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mWhat is the connection between WARREN A STEPHENS and Donald Trump?\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m      9\u001b[39m )\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(result.output)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\NicuCalcea\\Projects\\ddj-wiki\\.venv\\Lib\\site-packages\\pydantic_ai\\agent.py:274\u001b[39m, in \u001b[36mAgent.__init__\u001b[39m\u001b[34m(self, model, output_type, instructions, system_prompt, deps_type, name, model_settings, retries, output_retries, tools, mcp_servers, defer_model_check, end_strategy, instrument, **_deprecated_kwargs)\u001b[39m\n\u001b[32m    272\u001b[39m     \u001b[38;5;28mself\u001b[39m.model = model\n\u001b[32m    273\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m274\u001b[39m     \u001b[38;5;28mself\u001b[39m.model = \u001b[43mmodels\u001b[49m\u001b[43m.\u001b[49m\u001b[43minfer_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    276\u001b[39m \u001b[38;5;28mself\u001b[39m.end_strategy = end_strategy\n\u001b[32m    277\u001b[39m \u001b[38;5;28mself\u001b[39m.name = name\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\NicuCalcea\\Projects\\ddj-wiki\\.venv\\Lib\\site-packages\\pydantic_ai\\models\\__init__.py:460\u001b[39m, in \u001b[36minfer_model\u001b[39m\u001b[34m(model)\u001b[39m\n\u001b[32m    457\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m provider \u001b[38;5;129;01min\u001b[39;00m (\u001b[33m'\u001b[39m\u001b[33mdeepseek\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mopenai\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mazure\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m    458\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mopenai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OpenAIModel\n\u001b[32m--> \u001b[39m\u001b[32m460\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mOpenAIModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprovider\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprovider\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    461\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m provider \u001b[38;5;129;01min\u001b[39;00m (\u001b[33m'\u001b[39m\u001b[33mgoogle-gla\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mgoogle-vertex\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m    462\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgemini\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GeminiModel\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\NicuCalcea\\Projects\\ddj-wiki\\.venv\\Lib\\site-packages\\pydantic_ai\\models\\openai.py:182\u001b[39m, in \u001b[36mOpenAIModel.__init__\u001b[39m\u001b[34m(self, model_name, provider, system_prompt_role)\u001b[39m\n\u001b[32m    180\u001b[39m \u001b[38;5;28mself\u001b[39m._model_name = model_name\n\u001b[32m    181\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(provider, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m182\u001b[39m     provider = \u001b[43minfer_provider\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprovider\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    183\u001b[39m \u001b[38;5;28mself\u001b[39m.client = provider.client\n\u001b[32m    184\u001b[39m \u001b[38;5;28mself\u001b[39m.system_prompt_role = system_prompt_role\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\NicuCalcea\\Projects\\ddj-wiki\\.venv\\Lib\\site-packages\\pydantic_ai\\providers\\__init__.py:50\u001b[39m, in \u001b[36minfer_provider\u001b[39m\u001b[34m(provider)\u001b[39m\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m provider == \u001b[33m'\u001b[39m\u001b[33mopenai\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m     48\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mopenai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OpenAIProvider\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mOpenAIProvider\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m provider == \u001b[33m'\u001b[39m\u001b[33mdeepseek\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m     52\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdeepseek\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DeepSeekProvider\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\NicuCalcea\\Projects\\ddj-wiki\\.venv\\Lib\\site-packages\\pydantic_ai\\providers\\openai.py:67\u001b[39m, in \u001b[36mOpenAIProvider.__init__\u001b[39m\u001b[34m(self, base_url, api_key, openai_client, http_client)\u001b[39m\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     66\u001b[39m     http_client = cached_async_http_client(provider=\u001b[33m'\u001b[39m\u001b[33mopenai\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m     \u001b[38;5;28mself\u001b[39m._client = \u001b[43mAsyncOpenAI\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_url\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbase_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m=\u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_client\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhttp_client\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\NicuCalcea\\Projects\\ddj-wiki\\.venv\\Lib\\site-packages\\openai\\_client.py:419\u001b[39m, in \u001b[36mAsyncOpenAI.__init__\u001b[39m\u001b[34m(self, api_key, organization, project, base_url, websocket_base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[39m\n\u001b[32m    417\u001b[39m     api_key = os.environ.get(\u001b[33m\"\u001b[39m\u001b[33mOPENAI_API_KEY\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    418\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m api_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m419\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m OpenAIError(\n\u001b[32m    420\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    421\u001b[39m     )\n\u001b[32m    422\u001b[39m \u001b[38;5;28mself\u001b[39m.api_key = api_key\n\u001b[32m    424\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m organization \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[31mOpenAIError\u001b[39m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
          ]
        }
      ],
      "source": [
        "agent = Agent(\n",
        "    'openai:gpt-4.1-mini',\n",
        "    tools=[duckduckgo_search_tool()],\n",
        "    system_prompt='Answer the question to the best of your abilities, using DuckDuckGo search results.',\n",
        ")\n",
        "\n",
        "result = agent.run_sync(\n",
        "    'What is the connection between WARREN A STEPHENS and Donald Trump?'\n",
        ")\n",
        "print(result.output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Searching and scraping"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Large Language Models are prone to [hallucinations](https://en.wikipedia.org/wiki/Hallucination_(artificial_intelligence)). If you ask an LLM a question it doesn't know the answer to, [it will confidently make up a plausible-sounding answer](https://ddj.nicu.md/ai/) that is completely wrong. This is particularly the case with less known organisations that wouldn't feature promionently in the training data.\n",
        "\n",
        "Let's ask ChatGPT if \"Clean Resource Innovation Network\" is a fossil fuel organisation or not."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "org = \"Clean Resource Innovation Network\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "def make_request_openai_simple(prompt_system: str, prompt_user: str, model: str = \"gpt-4o-mini\", **kwargs) -> str:\n",
        "    client = OpenAI(\n",
        "        # api_key = ''\n",
        "        )\n",
        "    response = client.beta.chat.completions.parse(\n",
        "        model=model,\n",
        "        temperature=0,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": prompt_system},\n",
        "            {\"role\": \"user\", \"content\": prompt_user}\n",
        "        ]\n",
        "    )\n",
        "    return response.choices[0].message.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'NO'"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "make_request_openai_simple(prompt_system=\"You are an AI whose job it is to help researchers identify fossil fuel organisations\",\n",
        "                           prompt_user=f\"Is ${org} a fossil fuel organisation? Respond with YES or NO\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "One way to minimise (but not completely eliminate) hallucinations is Retrieval-Augmented Generation (RAG). Very simply, this means providing the AI with some additional factual context for the question you're asking.\n",
        "\n",
        "One example comes from The San Francisco Chronicle, who launched [a chatbot that answers questions about Kamala Harris](https://www.sfchronicle.com/projects/2024/kamala-harris-election-questions/).\n",
        "\n",
        "In our case, we'll provide the AI with relevant search results related to our organisation so that it knows who we're asking about.\n",
        "\n",
        "We'll use DuckDuckGo because it has a free API. For better results, you can use the Google API or a [SERP API](https://developers.oxylabs.io/scraper-apis/serp-scraper-api/google/search)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfnNL0Lz-CAm"
      },
      "source": [
        "Let's search for the organisation and extract the first 5 results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hqns4x4ZOlON",
        "outputId": "9e761841-40d6-4b70-c874-2c99f9e925d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\"Clean Resource Innovation Network\" oil gas coal\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'title': 'Clean Resource Innovation Network',\n",
              "  'href': 'https://www.cleanresourceinnovation.com/',\n",
              "  'body': 'The Clean Resource Innovation Network (CRIN) is a pan-Canadian network founded to enable cleaner energy development by commercializing and adopting technologies for the oil and gas industry. We bring together diverse expertise from industry, entrepreneurs, investors, academia, governments, and many others to enable solutions that improve the ...'},\n",
              " {'title': '17 new technologies funded by CRIN competition to address economic ...',\n",
              "  'href': 'https://energynow.ca/2022/03/17-new-technologies-funded-by-crin-competition-to-address-economic-challenges-of-canadas-oil-and-gas-industry/',\n",
              "  'body': \"March 9, 2022 CALGARY, Alberta - Clean Resource Innovation Network (CRIN) Today CRIN is announcing funding of over $44 million CAD for 17 projects identified through its Reducing Environmental Footprint oil and gas technology competition. This brings the total investment through three competitions to $80 million. CRIN's competitions are designed to…\"},\n",
              " {'title': 'CRIN Funds an Additional Nineteen Projects through the Oil - GlobeNewswire',\n",
              "  'href': 'https://www.globenewswire.com/news-release/2023/11/03/2773454/0/en/CRIN-Funds-an-Additional-Nineteen-Projects-through-the-Oil-Gas-Technology-Competitions.html',\n",
              "  'body': 'The Clean Resource Innovation Network (CRIN) is proud to announce the funding of nineteen (19) additional high-impact projects, totaling $16.1 million CAD in support. With this new commitment ...'},\n",
              " {'title': 'New technologies identified for funding by CRIN competitions will ...',\n",
              "  'href': 'https://energynow.ca/2022/01/new-technologies-identified-for-funding-by-crin-competitions-will-enable-emissions-reduction-and-improve-safety-in-oil-and-gas/',\n",
              "  'body': \"CALGARY, Alberta, Jan. 26, 2022 (GLOBE NEWSWIRE) -- Clean Resource Innovation Network (CRIN) Achieving CRIN's goal of reducing 100 megatonnes of CO2 equivalent (CO2e) emissions from producing Canada's oil and gas resources by 2033 is within reach! Today, CRIN is announcing the first projects identified for funding awards through CRIN's $80…\"},\n",
              " {'title': 'Clean Resource Innovation Network (CRIN) on LinkedIn: Oil & Gas ...',\n",
              "  'href': 'https://www.linkedin.com/posts/crin_oil-gas-cleantech-challenge-activity-7231359278865952768-q2m_',\n",
              "  'body': 'The 2024 Colorado Oil & Gas Cleantech Challenge, ... Clean Resource Innovation Network (CRIN) 7,102 followers 2d Report this post The 2024 Colorado Oil & Gas Cleantech Challenge, a product ...'}]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "search = f'\"{org}\" oil gas coal'\n",
        "print(search)\n",
        "\n",
        "results = DDGS().text(search, max_results=5)\n",
        "results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQ8RuuUtRLRM"
      },
      "source": [
        "## Scrape search results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7md6GzFU-KJn"
      },
      "source": [
        "Now, we want to extract the text from each of those URLs. We'll use [Trafilatura](https://github.com/adbar/trafilatura), a library that will help us extract the main text without headers, footers and other irrelevant text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "z4MoJ3M7ASIa"
      },
      "outputs": [],
      "source": [
        "def extract_text(urls):\n",
        "    results = []\n",
        "\n",
        "    for url in urls:\n",
        "        print(f\"Scraping {url}...\")\n",
        "        try:\n",
        "            response = requests.get(url, timeout=30, verify=False)  # Note: verify=False is not recommended for production use\n",
        "            response.raise_for_status()  # Raises an HTTPError for bad responses\n",
        "            extracted_text = extract(response.text, output_format=\"markdown\")\n",
        "            results.append((url, extracted_text))\n",
        "        except requests.RequestException as e:\n",
        "            print(f\"Error scraping {url}: {str(e)}\")\n",
        "            results.append((url, f\"Error: {str(e)}\"))\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "id": "4k7Y36ARAxED",
        "outputId": "00496a96-727a-4bca-afbf-c0c8cde94754"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Scraping https://www.cleanresourceinnovation.com/...\n",
            "Scraping https://energynow.ca/2022/03/17-new-technologies-funded-by-crin-competition-to-address-economic-challenges-of-canadas-oil-and-gas-industry/...\n",
            "Error scraping https://energynow.ca/2022/03/17-new-technologies-funded-by-crin-competition-to-address-economic-challenges-of-canadas-oil-and-gas-industry/: 403 Client Error: Forbidden for url: https://energynow.ca/2022/03/17-new-technologies-funded-by-crin-competition-to-address-economic-challenges-of-canadas-oil-and-gas-industry/\n",
            "Scraping https://www.globenewswire.com/news-release/2023/11/03/2773454/0/en/CRIN-Funds-an-Additional-Nineteen-Projects-through-the-Oil-Gas-Technology-Competitions.html...\n",
            "Scraping https://energynow.ca/2022/01/new-technologies-identified-for-funding-by-crin-competitions-will-enable-emissions-reduction-and-improve-safety-in-oil-and-gas/...\n",
            "Error scraping https://energynow.ca/2022/01/new-technologies-identified-for-funding-by-crin-competitions-will-enable-emissions-reduction-and-improve-safety-in-oil-and-gas/: 403 Client Error: Forbidden for url: https://energynow.ca/2022/01/new-technologies-identified-for-funding-by-crin-competitions-will-enable-emissions-reduction-and-improve-safety-in-oil-and-gas/\n",
            "Scraping https://www.linkedin.com/posts/crin_oil-gas-cleantech-challenge-activity-7231359278865952768-q2m_...\n"
          ]
        }
      ],
      "source": [
        "# Run the function\n",
        "texts = extract_text([result['href'] for result in results if 'href' in result])\n",
        "texts = [(url, text) for url, text in texts if text is not None] # remove empty scrapes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "wtXtccX8F248"
      },
      "outputs": [],
      "source": [
        "# Paste text together\n",
        "prompt_documents = \"\\n\\n\".join(f\"URL: {url}\\n{text}\" for url, text in texts).strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "nmkHoU6nSxy3"
      },
      "outputs": [],
      "source": [
        "prompt_system = 'You will be provided with a collection of documents collected from Google search results. Your task is to determine whether an organization is a fossil fuel company or lobbying group or not.'\n",
        "\n",
        "prompt_instructions= f'''\n",
        "## Instructions\n",
        "\n",
        "You are a researcher investigating whether \"{org}\" is a fossil fuel organization.\n",
        "\n",
        "A fossil fuel organization:\n",
        "- Aims to influence policy or legislation in the interests of fossil fuel companies and shareholders.\n",
        "- Has significant business activities in exploration, extraction, refining, trading, specialized transportation of oil, gas, coal, or blue hydrogen, or sale of electricity derived from them.\n",
        "- Publicly declares involvement in fossil fuels or promotes significant investments in such companies.\n",
        "- Can be an NGO, foundation, think tank, or lobbying group funded by fossil fuel companies or their executives.\n",
        "- May include larger companies that own fossil fuel subsidiaries (e.g., BASF owning Wintershall).\n",
        "- Includes companies selling energy from fossil fuels (e.g., Octopus Energy).\n",
        "- Companies that currently produce or sell fossil fuels, regardless of their plans to divest in the future.\n",
        "\n",
        "Analyze the text above, which was extracted from an internet search for \"{org}\", to determine if it is a fossil fuel organization. Use common sense and respond only in English, even if the original content is not in English.\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_riBT8RNSUsa"
      },
      "source": [
        "## Send request to LLM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20pt6-D3V2Vi"
      },
      "source": [
        "There are [various LLMs available](https://ddj.nicu.md/ai/llm-comparison.html), each with different capabilities and costs.\n",
        "\n",
        "For our task, there are a few things we need to consider:\n",
        "\n",
        "- **Performance**: Is the model intelligent enough to understand the task?\n",
        "- **Cost**: If you are running tens of thousands of requests, the cost can add up quickly. Models like Claude 3 Opus quickly become unaffordable.\n",
        "- **Rate limits**: Some platforms impose limits on how many times you can call the API in a given time period (minute, hour, day) and how big the requests can be.\n",
        "- **Other features**: Some models offer additional features like better support for various languages, prompt caching, or structured outputs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLJd9swFWveD"
      },
      "source": [
        "We'll use OpenAI's gpt-4o-mini for this classification. One advantage of this particular model is its support for [Structured Outputs](https://openai.com/index/introducing-structured-outputs-in-the-api/). This means you can force the response to follow a certain set of rules.\n",
        "\n",
        "Let's define what we want the output to be."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "8aCCEsEHW1il"
      },
      "outputs": [],
      "source": [
        "class Classification(BaseModel):\n",
        "    fossil_fuel_link: bool = Field(description = \"Is this a fossil fuel organization?\")\n",
        "    explanation: str = Field(description = \"A brief explanation of your decision, in English\")\n",
        "    source: str = Field(description = \"A link to the SINGLE most relevant source that supports your classification\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHxaIEwyX57y"
      },
      "source": [
        "Now, let's make the request to OpenAI. First, we define a function like we did before, with a few tweaks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "3PeFjHcNX9aP"
      },
      "outputs": [],
      "source": [
        "def make_request_openai(prompt_system: str, prompt_instructions: str, prompt_documents: str, model: str = \"gpt-4o-mini\", **kwargs) -> str:\n",
        "    \"\"\"Make a request to OpenAI models that support structured outputs.\"\"\"\n",
        "    client = OpenAI(\n",
        "        # api_key = ''\n",
        "        )\n",
        "    response = client.beta.chat.completions.parse(\n",
        "        model=model,\n",
        "        temperature=0,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": prompt_system},\n",
        "            {\"role\": \"user\", \"content\": f'${prompt_documents}\\n\\n${prompt_instructions}'}\n",
        "        ],\n",
        "        response_format=Classification\n",
        "    )\n",
        "    return response.choices[0].message.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Jd28bzRYrrm"
      },
      "source": [
        "Now, let's run the function on our example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "mAKgSk4RYwcO"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\"fossil_fuel_link\":true,\"explanation\":\"The Clean Resource Innovation Network (CRIN) is focused on enabling cleaner energy development specifically for the oil and gas industry. It supports projects that aim to improve the environmental performance of this sector, which indicates a direct involvement with fossil fuels. The organization is dedicated to commercializing technologies that benefit the oil and gas industry, which aligns with the characteristics of a fossil fuel organization.\",\"source\":\"https://www.cleanresourceinnovation.com/\"}\n"
          ]
        }
      ],
      "source": [
        "openai_response = make_request_openai(prompt_system, prompt_instructions, prompt_documents)\n",
        "print(openai_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OonRh1nRZjy1"
      },
      "source": [
        "# Scale"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJc-HjyeZqhZ"
      },
      "source": [
        "We've seen an example of how to classify one organisation. The advantage of using AI is that we can scale this to (hundreds of) thousands of operations.\n",
        "\n",
        "Let's define a few functions to help us with this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "NelSf-csZlJj"
      },
      "outputs": [],
      "source": [
        "def classify_org(org: str):\n",
        "    search = f'\"{org}\" oil gas coal'\n",
        "\n",
        "    results = DDGS().text(search, max_results=5)\n",
        "\n",
        "    texts = extract_text([result['href'] for result in results if 'href' in result])\n",
        "    texts = [(url, text) for url, text in texts if text is not None] # remove empty scrapes\n",
        "\n",
        "    prompt_documents = \"\\n\\n\".join(f\"URL: {url}\\n{text}\" for url, text in texts).strip()\n",
        "    prompt_instructions= f'''\n",
        "## Instructions\n",
        "\n",
        "You are a researcher investigating whether \"{org}\" is a fossil fuel organization.\n",
        "\n",
        "A fossil fuel organization:\n",
        "- Aims to influence policy or legislation in the interests of fossil fuel companies and shareholders.\n",
        "- Has significant business activities in exploration, extraction, refining, trading, specialized transportation of oil, gas, coal, or blue hydrogen, or sale of electricity derived from them.\n",
        "- Publicly declares involvement in fossil fuels or promotes significant investments in such companies.\n",
        "- Can be an NGO, foundation, think tank, or lobbying group funded by fossil fuel companies or their executives.\n",
        "- May include larger companies that own fossil fuel subsidiaries (e.g., BASF owning Wintershall).\n",
        "- Includes companies selling energy from fossil fuels (e.g., Octopus Energy).\n",
        "- Companies that currently produce or sell fossil fuels, regardless of their plans to divest in the future.\n",
        "\n",
        "Analyze the text above, which was extracted from an internet search for \"{org}\", to determine if it is a fossil fuel organization. Use common sense and respond only in English, even if the original content is not in English.\n",
        "'''\n",
        "\n",
        "    openai_response = make_request_openai(prompt_system, prompt_instructions, prompt_documents)\n",
        "\n",
        "    return openai_response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "-fgR-Ge-bLgr"
      },
      "outputs": [],
      "source": [
        "def apply_classify_org(df):\n",
        "    df['classification'] = df.apply(lambda row: classify_org(org = row['organization']), axis=1)\n",
        "    df['classification'] = df['classification'].apply(json.loads)\n",
        "    df = pd.concat([df.drop(['classification'], axis=1), df['classification'].apply(pd.Series)], axis=1)\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rm4LvIJvaVsz"
      },
      "source": [
        "Now let's run this on our sample of organisations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EPOyJWn4bjSK",
        "outputId": "87573f71-ee28-4b5b-97f9-23a86fd8ed88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Scraping https://climatereality.ph/reenergizeph/...\n",
            "Scraping https://climatereality.ph/2021/08/21/climate-reality-ph-geop-a-potent-weapon-against-unreliable-coal-sourced-power/...\n",
            "Scraping https://climatereality.ph/2023/09/28/climate-reality-ph-builds-momentum-for-geop-implementation-in-mindanao/...\n",
            "Scraping https://mirror.pia.gov.ph/news/2021/08/22/climate-reality-geop-a-potent-weapon-vscoal-sourced-power...\n",
            "Scraping https://www.facebook.com/climaterealityphilippines/posts/green-energy-option-program-a-potent-weapon-against-unreliable-coal-sourced-powe/4243220149098727/...\n"
          ]
        }
      ],
      "source": [
        "cop_orgs_classified = apply_classify_org(cop_orgs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>organization</th>\n",
              "      <th>fossil_fuel_link</th>\n",
              "      <th>explanation</th>\n",
              "      <th>source</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>37190</th>\n",
              "      <td>IUCN Regional Office for West Asia</td>\n",
              "      <td>False</td>\n",
              "      <td>The IUCN Regional Office for West Asia is prim...</td>\n",
              "      <td>https://www.iucn.org/regions/west-asia</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33297</th>\n",
              "      <td>The Climate Reality Project Philippines</td>\n",
              "      <td>False</td>\n",
              "      <td>The Climate Reality Project Philippines focuse...</td>\n",
              "      <td>https://climatereality.ph/reenergizeph/</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18860</th>\n",
              "      <td>Seychelles Meteorological Authorithy</td>\n",
              "      <td>False</td>\n",
              "      <td>The Seychelles Meteorological Authority is a g...</td>\n",
              "      <td>https://www.seychelles.gov.sc/Departments/mete...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7675</th>\n",
              "      <td>Ministry of Local Government, Lands, Regional ...</td>\n",
              "      <td>False</td>\n",
              "      <td>The Ministry of Local Government, Lands, Regio...</td>\n",
              "      <td>https://www.example.com/ministry-local-government</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23338</th>\n",
              "      <td>Chairperson s Secretariat</td>\n",
              "      <td>False</td>\n",
              "      <td>The 'Chairperson's Secretariat' does not appea...</td>\n",
              "      <td>https://www.example.com/chairpersons-secretariat</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            organization  fossil_fuel_link  \\\n",
              "37190                 IUCN Regional Office for West Asia             False   \n",
              "33297            The Climate Reality Project Philippines             False   \n",
              "18860               Seychelles Meteorological Authorithy             False   \n",
              "7675   Ministry of Local Government, Lands, Regional ...             False   \n",
              "23338                          Chairperson s Secretariat             False   \n",
              "\n",
              "                                             explanation  \\\n",
              "37190  The IUCN Regional Office for West Asia is prim...   \n",
              "33297  The Climate Reality Project Philippines focuse...   \n",
              "18860  The Seychelles Meteorological Authority is a g...   \n",
              "7675   The Ministry of Local Government, Lands, Regio...   \n",
              "23338  The 'Chairperson's Secretariat' does not appea...   \n",
              "\n",
              "                                                  source  \n",
              "37190             https://www.iucn.org/regions/west-asia  \n",
              "33297            https://climatereality.ph/reenergizeph/  \n",
              "18860  https://www.seychelles.gov.sc/Departments/mete...  \n",
              "7675   https://www.example.com/ministry-local-government  \n",
              "23338   https://www.example.com/chairpersons-secretariat  "
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cop_orgs_classified"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "gBycL7EQdlbb",
        "outputId": "8d1f14dd-efd3-4a44-dbd8-5c3c81d905d2"
      },
      "outputs": [],
      "source": [
        "cop_orgs_classified.to_csv('data/cop_orgs_classified.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gi9oRpohdyI6"
      },
      "source": [
        "# What next?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KC-4gftBgRIz"
      },
      "source": [
        "There are lots of things we can improve about this process. Here are some ideas:\n",
        "\n",
        "- **Play around with the prompt**. \n",
        "- **Change search engine**. DuckDuckGo is free and good for a prototype. However, their API isn't meant to be used to this way and will often deny requests. It also doesn't return the best results. I recomment switching to Google.\n",
        "- **Try other models**. If you find that gpt-4o-mini is insufficient, you can use the smarter gpt-4o.\n",
        "- **Validate the output**. If you use other models without Structured Output support, you can use Guardrails to [validate their output](https://ddj.nicu.md/ai/python-validation.html). It also lets you validate other things, like the language of the output.\n",
        "- **Cache things**. Don't start over if something goes wrong, save the search results, scrapes and LLM outputs and continue where you left off.\n",
        "- **Multithreading**. You can use Python's [multithreading](https://docs.python.org/3/library/threading.html) to run multiple classifications in parallel, significantly speeding up the process.\n",
        "- **Verify**. LLMs are still dumb and shouldn't be trusted. Manually verify the classifications if you're going to publish the results!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
